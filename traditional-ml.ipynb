{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":6161672,"datasetId":3534886,"databundleVersionId":6240662}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install opencv-python scikit-image scikit-learn joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"sivm205/soybean-diseased-leaf-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:07:51.573935Z","iopub.execute_input":"2025-02-10T16:07:51.574378Z","iopub.status.idle":"2025-02-10T16:07:56.393863Z","shell.execute_reply.started":"2025-02-10T16:07:51.574339Z","shell.execute_reply":"2025-02-10T16:07:56.392567Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/soybean-diseased-leaf-dataset\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom skimage.feature import hog\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nimport joblib\n\ndef load_dataset(data_dir, image_size=(224, 224)):\n    \"\"\"\n    Loads images from a directory structure and extracts HOG features.\n    \n    Args:\n        data_dir (str): Path to the dataset directory.\n        image_size (tuple): Target size for resizing images (width, height).\n        \n    Returns:\n        features (np.ndarray): Array of extracted HOG features.\n        labels (np.ndarray): Array of corresponding class labels.\n        class_names (list): Sorted list of class names.\n    \"\"\"\n    features = []\n    labels = []\n    # List all subdirectories as classes (sorted for consistency)\n    class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n    class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n    \n    for cls in class_names:\n        cls_folder = os.path.join(data_dir, cls)\n        for fname in os.listdir(cls_folder):\n            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n                img_path = os.path.join(cls_folder, fname)\n                img = cv2.imread(img_path)\n                if img is None:\n                    continue\n                # Convert to grayscale for HOG feature extraction\n                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n                # Resize image\n                img_gray = cv2.resize(img_gray, image_size)\n                # Extract HOG features; you can adjust parameters as needed.\n                feature = hog(img_gray,\n                              orientations=9,\n                              pixels_per_cell=(8, 8),\n                              cells_per_block=(2, 2),\n                              block_norm='L2-Hys',\n                              visualize=False,\n                              feature_vector=True)\n                features.append(feature)\n                labels.append(class_to_idx[cls])\n                \n    return np.array(features), np.array(labels), class_names\n\ndef main():\n    # Update this path to your dataset directory\n    data_dir = \"/kaggle/input/soybean-diseased-leaf-dataset\"\n    print(\"Loading dataset and extracting HOG features...\")\n    X, y, class_names = load_dataset(data_dir, image_size=(224, 224))\n    print(f\"Dataset loaded. Number of samples: {len(y)}\")\n    print(\"Detected classes:\", class_names)\n    \n    # Split the dataset (80% train, 20% test) with stratification\n    X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                        test_size=0.2, \n                                                        random_state=42, \n                                                        stratify=y)\n    \n    # Define the classifiers to benchmark\n    models = {\n        'SVC': SVC(kernel='rbf', probability=True, random_state=42),\n        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n        'KNN': KNeighborsClassifier(n_neighbors=5)\n    }\n    \n    # Iterate over each model, train and evaluate\n    for name, model in models.items():\n        print(\"\\n==============================\")\n        print(f\"Training {name} classifier...\")\n        model.fit(X_train, y_train)\n        \n        # Save the trained model (optional)\n        joblib.dump(model, f\"{name}_model.joblib\")\n        \n        # Make predictions on the test set\n        y_pred = model.predict(X_test)\n        \n        # Compute metrics\n        acc = accuracy_score(y_test, y_pred)\n        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n        rec  = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n        f1   = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n        \n        print(f\"{name} Test Accuracy: {acc:.4f}\")\n        print(f\"{name} Precision:    {prec:.4f}\")\n        print(f\"{name} Recall:       {rec:.4f}\")\n        print(f\"{name} F1 Score:     {f1:.4f}\")\n        print(\"\\nClassification Report:\")\n        print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))\n    \nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T16:08:09.056592Z","iopub.execute_input":"2025-02-10T16:08:09.057230Z","iopub.status.idle":"2025-02-10T16:11:25.724556Z","shell.execute_reply.started":"2025-02-10T16:08:09.057191Z","shell.execute_reply":"2025-02-10T16:11:25.723384Z"}},"outputs":[{"name":"stdout","text":"Loading dataset and extracting HOG features...\nDataset loaded. Number of samples: 609\nDetected classes: ['Mossaic Virus', 'Southern blight', 'Sudden Death Syndrone', 'Yellow Mosaic', 'bacterial_blight', 'brown_spot', 'crestamento', 'ferrugen', 'powdery_mildew', 'septoria']\n\n==============================\nTraining SVC classifier...\nSVC Test Accuracy: 0.7705\nSVC Precision:    0.7600\nSVC Recall:       0.7705\nSVC F1 Score:     0.7365\n\nClassification Report:\n                       precision    recall  f1-score   support\n\n        Mossaic Virus       1.00      0.25      0.40         4\n      Southern blight       0.81      1.00      0.90        13\nSudden Death Syndrone       0.69      0.91      0.78        22\n        Yellow Mosaic       0.68      0.59      0.63        22\n     bacterial_blight       0.83      1.00      0.91        10\n           brown_spot       1.00      0.20      0.33         5\n          crestamento       0.00      0.00      0.00         1\n             ferrugen       1.00      0.69      0.82        13\n       powdery_mildew       0.77      0.96      0.86        28\n             septoria       0.00      0.00      0.00         4\n\n             accuracy                           0.77       122\n            macro avg       0.68      0.56      0.56       122\n         weighted avg       0.76      0.77      0.74       122\n\n\n==============================\nTraining RandomForest classifier...\nRandomForest Test Accuracy: 0.7705\nRandomForest Precision:    0.7486\nRandomForest Recall:       0.7705\nRandomForest F1 Score:     0.7365\n\nClassification Report:\n                       precision    recall  f1-score   support\n\n        Mossaic Virus       1.00      0.25      0.40         4\n      Southern blight       0.81      1.00      0.90        13\nSudden Death Syndrone       0.66      0.95      0.78        22\n        Yellow Mosaic       0.80      0.55      0.65        22\n     bacterial_blight       0.82      0.90      0.86        10\n           brown_spot       0.50      0.20      0.29         5\n          crestamento       0.00      0.00      0.00         1\n             ferrugen       0.91      0.77      0.83        13\n       powdery_mildew       0.79      0.96      0.87        28\n             septoria       0.00      0.00      0.00         4\n\n             accuracy                           0.77       122\n            macro avg       0.63      0.56      0.56       122\n         weighted avg       0.75      0.77      0.74       122\n\n\n==============================\nTraining LogisticRegression classifier...\nLogisticRegression Test Accuracy: 0.7705\nLogisticRegression Precision:    0.7339\nLogisticRegression Recall:       0.7705\nLogisticRegression F1 Score:     0.7442\n\nClassification Report:\n                       precision    recall  f1-score   support\n\n        Mossaic Virus       1.00      0.75      0.86         4\n      Southern blight       0.93      1.00      0.96        13\nSudden Death Syndrone       0.66      0.86      0.75        22\n        Yellow Mosaic       0.67      0.55      0.60        22\n     bacterial_blight       0.80      0.80      0.80        10\n           brown_spot       0.50      0.20      0.29         5\n          crestamento       0.00      0.00      0.00         1\n             ferrugen       0.80      0.92      0.86        13\n       powdery_mildew       0.84      0.93      0.88        28\n             septoria       0.00      0.00      0.00         4\n\n             accuracy                           0.77       122\n            macro avg       0.62      0.60      0.60       122\n         weighted avg       0.73      0.77      0.74       122\n\n\n==============================\nTraining KNN classifier...\nKNN Test Accuracy: 0.6639\nKNN Precision:    0.7000\nKNN Recall:       0.6639\nKNN F1 Score:     0.6121\n\nClassification Report:\n                       precision    recall  f1-score   support\n\n        Mossaic Virus       1.00      0.50      0.67         4\n      Southern blight       0.87      1.00      0.93        13\nSudden Death Syndrone       0.54      0.91      0.68        22\n        Yellow Mosaic       0.50      0.09      0.15        22\n     bacterial_blight       1.00      0.30      0.46        10\n           brown_spot       1.00      0.20      0.33         5\n          crestamento       0.10      1.00      0.18         1\n             ferrugen       0.72      1.00      0.84        13\n       powdery_mildew       0.81      0.93      0.87        28\n             septoria       0.00      0.00      0.00         4\n\n             accuracy                           0.66       122\n            macro avg       0.65      0.59      0.51       122\n         weighted avg       0.70      0.66      0.61       122\n\n","output_type":"stream"}],"execution_count":3}]}