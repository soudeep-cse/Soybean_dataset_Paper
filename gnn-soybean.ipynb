{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":6161672,"datasetId":3534886,"databundleVersionId":6240662}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow\n!pip install scikit-learn\n!pip install torch torchvision\n!pip install torch-geometric\n!pip install optuna\n!pip install scikit-learn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"sivm205/soybean-diseased-leaf-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T12:38:12.389768Z","iopub.execute_input":"2025-02-10T12:38:12.390151Z","iopub.status.idle":"2025-02-10T12:38:31.528726Z","shell.execute_reply.started":"2025-02-10T12:38:12.390114Z","shell.execute_reply":"2025-02-10T12:38:31.527541Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/soybean-diseased-leaf-dataset\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch_geometric.data import Data, DataLoader\nfrom torch.utils.data import random_split\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nimport optuna\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:06:04.392891Z","iopub.execute_input":"2025-02-10T13:06:04.393335Z","iopub.status.idle":"2025-02-10T13:06:05.267205Z","shell.execute_reply.started":"2025-02-10T13:06:04.393303Z","shell.execute_reply":"2025-02-10T13:06:05.266041Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Actual GCN start here.....","metadata":{}},{"cell_type":"code","source":"# -------------------------------\n# 1. Image-to-Graph Conversion Function\n# -------------------------------\n\ndef image_to_graph(image, patch_size=(16, 16)):\n    \"\"\"\n    Converts an image (H, W, C) into a graph.\n      - Splits the image into non-overlapping patches.\n      - Each patch becomes a node whose feature is the mean color of the patch.\n      - Nodes are connected to their immediate neighbors (up, down, left, right).\n\n    Args:\n        image (np.array): Input image as a numpy array (H, W, C).\n        patch_size (tuple): The (height, width) of each patch.\n\n    Returns:\n        data (torch_geometric.data.Data): Graph data object with node features (x) and edge_index.\n    \"\"\"\n    h, w, c = image.shape\n    ph, pw = patch_size\n    num_nodes_h = h // ph\n    num_nodes_w = w // pw\n    nodes = []\n    \n    # Compute a simple feature (mean color) for each patch\n    for i in range(num_nodes_h):\n        for j in range(num_nodes_w):\n            patch = image[i * ph:(i + 1) * ph, j * pw:(j + 1) * pw, :]\n            patch_feature = np.mean(patch, axis=(0, 1))\n            nodes.append(patch_feature)\n    nodes = np.array(nodes, dtype=np.float32)\n    \n    # Build edge_index based on 4-connected grid neighbors.\n    edge_index = []\n    for i in range(num_nodes_h):\n        for j in range(num_nodes_w):\n            node_idx = i * num_nodes_w + j\n            # Up neighbor\n            if i > 0:\n                neighbor = (i - 1) * num_nodes_w + j\n                edge_index.append([node_idx, neighbor])\n                edge_index.append([neighbor, node_idx])\n            # Down neighbor\n            if i < num_nodes_h - 1:\n                neighbor = (i + 1) * num_nodes_w + j\n                edge_index.append([node_idx, neighbor])\n                edge_index.append([neighbor, node_idx])\n            # Left neighbor\n            if j > 0:\n                neighbor = i * num_nodes_w + (j - 1)\n                edge_index.append([node_idx, neighbor])\n                edge_index.append([neighbor, node_idx])\n            # Right neighbor\n            if j < num_nodes_w - 1:\n                neighbor = i * num_nodes_w + (j + 1)\n                edge_index.append([node_idx, neighbor])\n                edge_index.append([neighbor, node_idx])\n    \n    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n    data = Data(x=torch.tensor(nodes, dtype=torch.float), edge_index=edge_index)\n    return data\n\n# -------------------------------\n# 2. Load the Actual Dataset from Disk\n# -------------------------------\n\ndef load_dataset(dataset_path, target_size=(128, 128), patch_size=(16, 16)):\n    \"\"\"\n    Loads images from the dataset directory and converts each image into a graph.\n\n    Args:\n        dataset_path (str): Path to the dataset directory.\n        target_size (tuple): Desired image size (height, width) after resizing.\n        patch_size (tuple): Patch size for graph conversion.\n\n    Returns:\n        dataset (list): List of torch_geometric.data.Data objects with graph representation and label.\n        num_classes (int): Total number of classes.\n    \"\"\"\n    dataset = []\n    # List subdirectories (each representing a class)\n    all_class_names = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n    all_class_names = sorted(all_class_names)  # Sorting for consistency\n    num_classes = len(all_class_names)\n    print(f\"Found classes: {all_class_names}\")\n    \n    for class_idx, class_name in enumerate(all_class_names):\n        class_folder = os.path.join(dataset_path, class_name)\n        # List all image files in the folder (consider jpg, jpeg, png)\n        for file_name in os.listdir(class_folder):\n            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n                file_path = os.path.join(class_folder, file_name)\n                try:\n                    # Open the image, convert to RGB, and resize\n                    with Image.open(file_path) as img:\n                        img = img.convert(\"RGB\")\n                        img = img.resize(target_size)\n                        image_np = np.array(img)\n                    \n                    # Convert image to graph representation\n                    graph_data = image_to_graph(image_np, patch_size=patch_size)\n                    # Set the label (as a tensor of shape [1])\n                    graph_data.y = torch.tensor([class_idx], dtype=torch.long)\n                    dataset.append(graph_data)\n                except Exception as e:\n                    print(f\"Error loading image {file_path}: {e}\")\n    print(f\"Total images loaded: {len(dataset)}\")\n    return dataset, num_classes\n\n# -------------------------------\n# 3. Define the GCN Model\n# -------------------------------\n\nclass GCN(torch.nn.Module):\n    def __init__(self, num_node_features, num_classes, num_layers, hidden_dim, dropout):\n        \"\"\"\n        GCN model with a variable number of GCNConv layers.\n        \n        Args:\n            num_node_features (int): Dimension of node features.\n            num_classes (int): Number of classes.\n            num_layers (int): Number of GCNConv layers.\n            hidden_dim (int): Hidden dimension size for each GCN layer.\n            dropout (float): Dropout rate.\n        \"\"\"\n        super(GCN, self).__init__()\n        self.convs = nn.ModuleList()\n        # First layer: from input features to hidden_dim\n        self.convs.append(GCNConv(num_node_features, hidden_dim))\n        for _ in range(num_layers - 1):\n            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n        self.dropout = dropout\n        self.fc = nn.Linear(hidden_dim, num_classes)\n    \n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        for conv in self.convs:\n            x = conv(x, edge_index)\n            x = F.relu(x)\n            x = F.dropout(x, p=self.dropout, training=self.training)\n        # Global pooling: aggregate node features for a graph-level representation.\n        x = global_mean_pool(x, batch)\n        x = self.fc(x)\n        return x\n\n# -------------------------------\n# 4. Hyperparameter Tuning with Optuna\n# -------------------------------\n\ndef objective(trial):\n    # Hyperparameter suggestions\n    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [16, 32, 64, 128])\n    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n    \n    num_epochs = 20\n    batch_size = 16\n\n    # Create a new model instance for this trial\n    model = GCN(num_node_features=num_features,\n                num_classes=num_classes,\n                num_layers=num_layers,\n                hidden_dim=hidden_dim,\n                dropout=dropout)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = torch.nn.CrossEntropyLoss()\n    \n    # Training loop for the trial\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * batch.num_graphs\n        total_loss /= len(train_dataset)\n        \n        # Validation evaluation\n        model.eval()\n        correct = 0\n        for batch in val_loader:\n            batch = batch.to(device)\n            out = model(batch)\n            pred = out.argmax(dim=1)\n            correct += (pred == batch.y).sum().item()\n        val_acc = correct / len(val_dataset)\n        \n        trial.report(val_acc, epoch)\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n    return val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T12:59:29.648097Z","iopub.execute_input":"2025-02-10T12:59:29.648505Z","iopub.status.idle":"2025-02-10T12:59:29.673320Z","shell.execute_reply.started":"2025-02-10T12:59:29.648478Z","shell.execute_reply":"2025-02-10T12:59:29.672269Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# -------------------------------\n# 5. Main Script: Data Loading, Tuning, and Final Evaluation\n# -------------------------------\n\nif __name__ == '__main__':\n    # --- Load the Dataset ---\n    dataset_path = '/kaggle/input/soybean-diseased-leaf-dataset'\n    target_size = (128, 128)  # Resize images to 128x128\n    patch_size = (16, 16)     # Split each image into 16x16 patches\n    dataset, num_classes = load_dataset(dataset_path, target_size, patch_size)\n    \n    if len(dataset) == 0:\n        raise RuntimeError(\"No images were loaded. Please check the dataset path and structure.\")\n    \n    # Determine number of node features from the first graph\n    num_features = dataset[0].x.shape[1]\n    print(f\"Number of node features: {num_features}, Number of classes: {num_classes}\")\n    \n    # --- Split the dataset: 70% train, 15% validation, 15% test ---\n    total_samples = len(dataset)\n    num_train = int(0.7 * total_samples)\n    num_val = int(0.15 * total_samples)\n    num_test = total_samples - num_train - num_val\n    \n    train_dataset, val_dataset, test_dataset = random_split(dataset, [num_train, num_val, num_test])\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n    test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n    \n    # --- Hyperparameter Tuning with Optuna ---\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=10, timeout=600)\n    \n    print(\"Best trial:\")\n    trial = study.best_trial\n    print(\"  Accuracy: {:.4f}\".format(trial.value))\n    print(\"  Best hyperparameters:\")\n    for key, value in trial.params.items():\n        print(f\"    {key}: {value}\")\n    \n    # --- Final Training on Train + Validation and Evaluation on Test ---\n    best_params = trial.params\n    num_layers = best_params[\"num_layers\"]\n    hidden_dim = best_params[\"hidden_dim\"]\n    dropout = best_params[\"dropout\"]\n    lr = best_params[\"lr\"]\n    num_epochs = 30  # Increase epochs for final training\n    \n    # Combine training and validation sets\n    train_val_dataset = train_dataset + val_dataset\n    train_val_loader = DataLoader(train_val_dataset, batch_size=16, shuffle=True)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    best_model = GCN(num_node_features=num_features,\n                     num_classes=num_classes,\n                     num_layers=num_layers,\n                     hidden_dim=hidden_dim,\n                     dropout=dropout).to(device)\n    \n    optimizer = torch.optim.Adam(best_model.parameters(), lr=lr)\n    criterion = torch.nn.CrossEntropyLoss()\n    \n    print(\"\\nTraining the final model...\")\n    for epoch in range(num_epochs):\n        best_model.train()\n        total_loss = 0\n        for batch in train_val_loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = best_model(batch)\n            loss = criterion(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * batch.num_graphs\n        total_loss /= len(train_val_dataset)\n        print(f\"Epoch {epoch+1:03d}, Loss: {total_loss:.4f}\")\n    \n    # Evaluate on the test set and compute additional metrics\n    best_model.eval()\n    correct = 0\n    all_preds = []\n    all_labels = []\n    \n    for batch in test_loader:\n        batch = batch.to(device)\n        out = best_model(batch)\n        preds = out.argmax(dim=1)\n        correct += (preds == batch.y).sum().item()\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(batch.y.cpu().numpy())\n    \n    test_acc = correct / len(test_dataset)\n    precision = precision_score(all_labels, all_preds, average='weighted')\n    recall = recall_score(all_labels, all_preds, average='weighted')\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    \n    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:06:13.298297Z","iopub.execute_input":"2025-02-10T13:06:13.298913Z","iopub.status.idle":"2025-02-10T13:09:30.802642Z","shell.execute_reply.started":"2025-02-10T13:06:13.298878Z","shell.execute_reply":"2025-02-10T13:09:30.801273Z"}},"outputs":[{"name":"stdout","text":"Found classes: ['Mossaic Virus', 'Southern blight', 'Sudden Death Syndrone', 'Yellow Mosaic', 'bacterial_blight', 'brown_spot', 'crestamento', 'ferrugen', 'powdery_mildew', 'septoria']\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n[I 2025-02-10 13:08:40,149] A new study created in memory with name: no-name-c68603f4-6066-4e06-8f97-ead65da98e18\n","output_type":"stream"},{"name":"stdout","text":"Total images loaded: 609\nNumber of node features: 3, Number of classes: 10\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-14-ff4b261e587a>:166: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n[I 2025-02-10 13:08:47,276] Trial 0 finished with value: 0.43956043956043955 and parameters: {'num_layers': 3, 'hidden_dim': 64, 'dropout': 0.2548101692595587, 'lr': 0.00011959656534643027}. Best is trial 0 with value: 0.43956043956043955.\n[I 2025-02-10 13:08:52,562] Trial 1 finished with value: 0.6593406593406593 and parameters: {'num_layers': 2, 'hidden_dim': 64, 'dropout': 0.15974465685926909, 'lr': 0.0002901492702205883}. Best is trial 1 with value: 0.6593406593406593.\n[I 2025-02-10 13:08:55,735] Trial 2 finished with value: 0.6593406593406593 and parameters: {'num_layers': 1, 'hidden_dim': 32, 'dropout': 0.2689440748855265, 'lr': 0.0002973629418660138}. Best is trial 1 with value: 0.6593406593406593.\n[I 2025-02-10 13:09:03,668] Trial 3 finished with value: 0.7692307692307693 and parameters: {'num_layers': 2, 'hidden_dim': 128, 'dropout': 0.15205484326417612, 'lr': 0.001197228695209071}. Best is trial 3 with value: 0.7692307692307693.\n[I 2025-02-10 13:09:10,991] Trial 4 finished with value: 0.7472527472527473 and parameters: {'num_layers': 3, 'hidden_dim': 64, 'dropout': 0.37147866053311585, 'lr': 0.009350064827248436}. Best is trial 3 with value: 0.7692307692307693.\n[I 2025-02-10 13:09:11,294] Trial 5 pruned. \n[I 2025-02-10 13:09:11,835] Trial 6 pruned. \n[I 2025-02-10 13:09:12,124] Trial 7 pruned. \n[I 2025-02-10 13:09:12,539] Trial 8 pruned. \n[I 2025-02-10 13:09:16,742] Trial 9 pruned. \n","output_type":"stream"},{"name":"stdout","text":"Best trial:\n  Accuracy: 0.7692\n  Best hyperparameters:\n    num_layers: 2\n    hidden_dim: 128\n    dropout: 0.15205484326417612\n    lr: 0.001197228695209071\n\nTraining the final model...\nEpoch 001, Loss: 3.1987\nEpoch 002, Loss: 1.8745\nEpoch 003, Loss: 1.3400\nEpoch 004, Loss: 1.0511\nEpoch 005, Loss: 0.9839\nEpoch 006, Loss: 0.8991\nEpoch 007, Loss: 0.8177\nEpoch 008, Loss: 0.7821\nEpoch 009, Loss: 0.8508\nEpoch 010, Loss: 0.7822\nEpoch 011, Loss: 0.7867\nEpoch 012, Loss: 0.7342\nEpoch 013, Loss: 0.6959\nEpoch 014, Loss: 0.6576\nEpoch 015, Loss: 0.6503\nEpoch 016, Loss: 0.5920\nEpoch 017, Loss: 0.5724\nEpoch 018, Loss: 0.5747\nEpoch 019, Loss: 0.5701\nEpoch 020, Loss: 0.5405\nEpoch 021, Loss: 0.5402\nEpoch 022, Loss: 0.5111\nEpoch 023, Loss: 0.4891\nEpoch 024, Loss: 0.4950\nEpoch 025, Loss: 0.5006\nEpoch 026, Loss: 0.6009\nEpoch 027, Loss: 0.5129\nEpoch 028, Loss: 0.4633\nEpoch 029, Loss: 0.4533\nEpoch 030, Loss: 0.4649\n\nTest Accuracy: 0.9130\nPrecision: 0.9076\nRecall: 0.9130\nF1 Score: 0.9022\n","output_type":"stream"}],"execution_count":18}]}